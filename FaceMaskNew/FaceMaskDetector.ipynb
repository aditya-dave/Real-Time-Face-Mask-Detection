{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "FaceMaskDetector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atp74Ai4FKw9"
      },
      "source": [
        "##Setup Paths, Mount Google Drive, Resolve Dependencies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6pufFU9FODT",
        "outputId": "4490d2f4-4ed6-408b-c203-dc6b5f025698"
      },
      "source": [
        "#Mount Google Drive to our project in colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhAkNrmGFKw-"
      },
      "source": [
        "#Define the common paths being used.\n",
        "WORKSPACE_PATH = '/content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow/workspace'\n",
        "SCRIPTS_PATH = '/content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow/scripts'\n",
        "APIMODEL_PATH = '/content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow/models'\n",
        "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
        "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
        "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
        "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
        "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
        "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MulzgEi2KFz7"
      },
      "source": [
        "#Install tensorflow-object-detection-api in our models folder\n",
        "%cd /content/drive/MyDrive/Applie ML/FaceMaskNew/Tensorflow/workspace/models/\n",
        "!pip install tensorflow-object-detection-api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWR7tgMaVv87",
        "outputId": "8612b7f2-db06-446d-b6a9-cb69a86e5409"
      },
      "source": [
        "#Navigate to the Tensorflow/models/research folder\n",
        "%cd /content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52qi4V7IKGv_",
        "outputId": "790b2c41-23d2-4e85-8101-ca972cd89a2d"
      },
      "source": [
        "#Removing new version of tensorflow and installing tensorflow 1.14 due to compatibility issues.\n",
        "!pip show tensorflow\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.5.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: opt-einsum, typing-extensions, six, absl-py, flatbuffers, protobuf, tensorflow-estimator, tensorboard, wrapt, gast, numpy, google-pasta, termcolor, astunparse, keras-nightly, wheel, keras-preprocessing, h5py, grpcio\n",
            "Required-by: tensorflow-object-detection-api, kapre\n",
            "Found existing installation: tensorflow 2.5.0\n",
            "Uninstalling tensorflow-2.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 32 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.34.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 72.9 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.6.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.5.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiF917SnV8Bj"
      },
      "source": [
        "#Setup and install protoc.\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF5G4C8JWZIM"
      },
      "source": [
        "!cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtfZ4LWcWbkC",
        "outputId": "a0f1a419-85ee-4e33-ed5f-2a6b9c02430b"
      },
      "source": [
        "!python3 -m pip install --user --use-feature=2020-resolver ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Processing /content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.5.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 67.8 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 70.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 69.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow>=2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.32.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 66.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 71.4 MB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 733 kB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1660307 sha256=d5d0675096a1fb0f0759f697309584e9c2fc85d70efd8af5353f298d45ccfc4b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sq30c189/wheels/d2/26/8f/88e9e6240cdc75c24e6a5fe5e6a0787e08f749bc3478581e70\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=286a1f8a879857c0e299af39870dadf55aedeef7137d1243702b7f228fbc35da\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=d4593ed5c689e5b17295dcb30e846454431ed2127d10d417abc38ba0c5466eff\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=e5a72cba4abff3bead1a8d7f79f0a2f025ba5667dde8ed509dcfbbfff49a3e40\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c1e9b037b228a15d0eb4d514141a046292ed9e24c8ac142521b77c283ba37b25\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=7126bd95dc5d05cb931dea4f3362855bf1781cccad0edcb282484d12d4e996b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n",
            "Installing collected packages: requests, tensorflow-estimator, tensorboard, portalocker, future, dill, tf-slim, tensorflow-model-optimization, tensorflow-addons, tensorflow, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n",
            "\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script sacrebleu is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script cpuinfo is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts hdfscli and hdfscli-avro are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script fastavro is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.31.0 avro-python3-1.9.2.1 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.6.0 tensorflow-2.5.0 tensorflow-addons-0.13.0 tensorflow-estimator-2.5.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.1 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-2tDpbPvb4d",
        "outputId": "da170e5c-c85a-4073-9d20-89c277485d3a"
      },
      "source": [
        "#Resolving dependencies\n",
        "%cd /content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ5kiUv-uGri",
        "outputId": "cb8efd15-fde8-42d7-cbd3-10f08990ce79"
      },
      "source": [
        "#Resolving dependencies\n",
        "%cd /content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research\n",
        "!pip install git+https://github.com/google-research/tf-slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research\n",
            "Collecting git+https://github.com/google-research/tf-slim\n",
            "  Cloning https://github.com/google-research/tf-slim to /tmp/pip-req-build-kz9p7lg4\n",
            "  Running command git clone -q https://github.com/google-research/tf-slim /tmp/pip-req-build-kz9p7lg4\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim==1.2.0) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf-slim==1.2.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCT9_Wqy2Ist",
        "outputId": "5298b170-ed27-497d-9d23-617f0ab0cec2"
      },
      "source": [
        "#Resolving dependencies\n",
        "%cd /content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research\n",
        "!pip install git+https://github.com/google-research/tf-slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research\n",
            "Collecting git+https://github.com/google-research/tf-slim\n",
            "  Cloning https://github.com/google-research/tf-slim to /tmp/pip-req-build-zadvtgyz\n",
            "  Running command git clone -q https://github.com/google-research/tf-slim /tmp/pip-req-build-zadvtgyz\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim==1.2.0) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf-slim==1.2.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wC8AJNNFKw_"
      },
      "source": [
        "# 1. Create Label Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX3a7YGZ8-RA"
      },
      "source": [
        "##Create Label Map and generate TF records. Since this was giving issues we have run this locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwvS3U9pFKxA"
      },
      "source": [
        "# labels = [{'name':'Face_mask_found', 'id':1}, {'name':'Face_mask_not_found', 'id':2}]\n",
        "\n",
        "# with open(ANNOTATION_PATH + '\\label_map.pbtxt', 'w') as f:\n",
        "#     for label in labels:\n",
        "#         f.write('item { \\n')\n",
        "#         f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "#         f.write('\\tid:{}\\n'.format(label['id']))\n",
        "#         f.write('}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVMvPJcAH1KF"
      },
      "source": [
        "# %cd /\n",
        "# !python '/content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow/scripts/generate_tfrecord.py' -x '/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/images/train' -l '/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/label_map.pbtxt' -o '/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/train.record'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb8jLdJ1FKxA"
      },
      "source": [
        "# 2. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzOTNbdkFKxB"
      },
      "source": [
        "!python '/content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow/scripts/generate_tfrecord.py' -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/labelmap.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
        "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x{IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pyYtLV6FKxD"
      },
      "source": [
        "# 3. Download TF Models Pretrained Models from Tensorflow Model Zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "904GeRNXFKxE",
        "outputId": "1b22e62e-3b7d-4707-92c6-7a1f72383da7"
      },
      "source": [
        "#Clone the github repo for tensorflow models. This contains all the required files for transfer learning.\n",
        "\n",
        "!cd '/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow' && git clone https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 60015, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 60015 (delta 12), reused 16 (delta 0), pack-reused 59987\u001b[K\n",
            "Receiving objects: 100% (60015/60015), 573.68 MiB | 13.48 MiB/s, done.\n",
            "Resolving deltas: 100% (41751/41751), done.\n",
            "Checking out files: 100% (2594/2594), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQS7SQrg9nGg"
      },
      "source": [
        "## We have selected the ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8 pre-trained model here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U7ECb9aFKxF"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J8As_DFFKxG"
      },
      "source": [
        "#Created a new directory for the copying the config file of the pretrained model\n",
        "\n",
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-IalAk1FKxG"
      },
      "source": [
        "!mkdir {'Tensorflow\\workspace\\models\\\\'+CUSTOM_MODEL_NAME}\n",
        "!cp {PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {MODEL_PATH+'/'+CUSTOM_MODEL_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxRBlplTFKxG"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-9lb7c2FKxH"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qp9r9D0FKxH"
      },
      "source": [
        "#Config path of our pipeline.config that we copied to our new directory.\n",
        "CONFIG_PATH = '/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DefpaKRFKxH"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "r3AVusu3FKxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62cf2063-b522-4e16-b67a-82178bed412c"
      },
      "source": [
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/labelmap.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/test.record\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/labelmap.pbtxt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/test.record\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 2\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 4\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"detection\",\n",
              " 'train_input_config': label_map_path: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/labelmap.pbtxt\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/train.record\"\n",
              " }}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlNulqIJFKxI"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlaMYUuNFKxI"
      },
      "source": [
        "#Making appropriate changes to our pipeline.config file according to our project.\n",
        "\n",
        "pipeline_config.model.ssd.num_classes = 2\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
        "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHXXtivsFKxI"
      },
      "source": [
        "#Writing the changes.\n",
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AacFoM-bFKxJ"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCg-u8JIFKxJ",
        "outputId": "2838ccc6-e3f6-4af2-ddde-84589ff03a4a"
      },
      "source": [
        "print(\"\"\"python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=5000\"\"\".format(APIMODEL_PATH, MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ0aJozjTe8Y",
        "outputId": "65720d42-48c8-4d55-9952-e287e0488ae2"
      },
      "source": [
        "#Passing the correct paths as arguments and training the model. \n",
        "\n",
        "%cd /content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow/\n",
        "!python models/research/object_detection/model_main_tf2.py --model_dir=workspace/models/my_ssd_mobnet --pipeline_config_path=workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Applied ML/FaceMaskNew/Tensorflow\n",
            "2021-08-09 15:18:28.936191: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-09 15:18:31.530106: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-09 15:18:31.540315: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-08-09 15:18:31.540360: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dc46ddd6b201): /proc/driver/nvidia/version does not exist\n",
            "2021-08-09 15:18:31.540713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0809 15:18:31.544901 140485712877440 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "W0809 15:18:31.545176 140485712877440 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0809 15:18:31.547945 140485712877440 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0809 15:18:31.845527 140485712877440 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0809 15:18:31.845760 140485712877440 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0809 15:18:31.869722 140485712877440 deprecation.py:336] From /root/.local/lib/python3.7/site-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/train.record']\n",
            "I0809 15:18:32.018579 140485712877440 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/train.record']\n",
            "I0809 15:18:32.019170 140485712877440 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0809 15:18:32.019302 140485712877440 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0809 15:18:32.019374 140485712877440 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0809 15:18:32.021943 140485712877440 deprecation.py:336] From /root/.local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0809 15:18:32.047301 140485712877440 deprecation.py:336] From /root/.local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0809 15:18:39.770179 140485712877440 deprecation.py:336] From /root/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0809 15:18:43.275196 140485712877440 deprecation.py:336] From /root/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0809 15:18:45.163560 140485712877440 deprecation.py:336] From /root/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-08-09 15:18:48.403984: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-08-09 15:18:48.408390: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
            "/root/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /root/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0809 15:19:11.757032 140476336158464 deprecation.py:534] From /root/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.923s\n",
            "I0809 15:20:43.632506 140485712877440 model_lib_v2.py:700] Step 100 per-step time 0.923s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1189464,\n",
            " 'Loss/localization_loss': 0.1016004,\n",
            " 'Loss/regularization_loss': 0.15386029,\n",
            " 'Loss/total_loss': 0.3744071,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0809 15:20:43.632891 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.1189464,\n",
            " 'Loss/localization_loss': 0.1016004,\n",
            " 'Loss/regularization_loss': 0.15386029,\n",
            " 'Loss/total_loss': 0.3744071,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.656s\n",
            "I0809 15:21:49.191495 140485712877440 model_lib_v2.py:700] Step 200 per-step time 0.656s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13838899,\n",
            " 'Loss/localization_loss': 0.074894994,\n",
            " 'Loss/regularization_loss': 0.1535673,\n",
            " 'Loss/total_loss': 0.3668513,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0809 15:21:49.191832 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.13838899,\n",
            " 'Loss/localization_loss': 0.074894994,\n",
            " 'Loss/regularization_loss': 0.1535673,\n",
            " 'Loss/total_loss': 0.3668513,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.607s\n",
            "I0809 15:22:49.865366 140485712877440 model_lib_v2.py:700] Step 300 per-step time 0.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1355618,\n",
            " 'Loss/localization_loss': 0.081147455,\n",
            " 'Loss/regularization_loss': 0.15320612,\n",
            " 'Loss/total_loss': 0.3699154,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0809 15:22:49.865696 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.1355618,\n",
            " 'Loss/localization_loss': 0.081147455,\n",
            " 'Loss/regularization_loss': 0.15320612,\n",
            " 'Loss/total_loss': 0.3699154,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.615s\n",
            "I0809 15:23:51.389681 140485712877440 model_lib_v2.py:700] Step 400 per-step time 0.615s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13224769,\n",
            " 'Loss/localization_loss': 0.06485325,\n",
            " 'Loss/regularization_loss': 0.1527912,\n",
            " 'Loss/total_loss': 0.34989214,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0809 15:23:51.390019 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.13224769,\n",
            " 'Loss/localization_loss': 0.06485325,\n",
            " 'Loss/regularization_loss': 0.1527912,\n",
            " 'Loss/total_loss': 0.34989214,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.610s\n",
            "I0809 15:24:52.419939 140485712877440 model_lib_v2.py:700] Step 500 per-step time 0.610s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07507281,\n",
            " 'Loss/localization_loss': 0.028213833,\n",
            " 'Loss/regularization_loss': 0.1523279,\n",
            " 'Loss/total_loss': 0.25561455,\n",
            " 'learning_rate': 0.053333}\n",
            "I0809 15:24:52.420278 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.07507281,\n",
            " 'Loss/localization_loss': 0.028213833,\n",
            " 'Loss/regularization_loss': 0.1523279,\n",
            " 'Loss/total_loss': 0.25561455,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.609s\n",
            "I0809 15:25:53.270121 140485712877440 model_lib_v2.py:700] Step 600 per-step time 0.609s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11491436,\n",
            " 'Loss/localization_loss': 0.047429577,\n",
            " 'Loss/regularization_loss': 0.15177467,\n",
            " 'Loss/total_loss': 0.31411862,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0809 15:25:53.270432 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.11491436,\n",
            " 'Loss/localization_loss': 0.047429577,\n",
            " 'Loss/regularization_loss': 0.15177467,\n",
            " 'Loss/total_loss': 0.31411862,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.608s\n",
            "I0809 15:26:54.024664 140485712877440 model_lib_v2.py:700] Step 700 per-step time 0.608s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.081317514,\n",
            " 'Loss/localization_loss': 0.027087057,\n",
            " 'Loss/regularization_loss': 0.15118705,\n",
            " 'Loss/total_loss': 0.25959164,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0809 15:26:54.024992 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.081317514,\n",
            " 'Loss/localization_loss': 0.027087057,\n",
            " 'Loss/regularization_loss': 0.15118705,\n",
            " 'Loss/total_loss': 0.25959164,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.606s\n",
            "I0809 15:27:54.673657 140485712877440 model_lib_v2.py:700] Step 800 per-step time 0.606s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0880405,\n",
            " 'Loss/localization_loss': 0.03628372,\n",
            " 'Loss/regularization_loss': 0.15059677,\n",
            " 'Loss/total_loss': 0.274921,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0809 15:27:54.674047 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.0880405,\n",
            " 'Loss/localization_loss': 0.03628372,\n",
            " 'Loss/regularization_loss': 0.15059677,\n",
            " 'Loss/total_loss': 0.274921,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.603s\n",
            "I0809 15:28:55.014273 140485712877440 model_lib_v2.py:700] Step 900 per-step time 0.603s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.094370894,\n",
            " 'Loss/localization_loss': 0.033451375,\n",
            " 'Loss/regularization_loss': 0.14993273,\n",
            " 'Loss/total_loss': 0.277755,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0809 15:28:55.014656 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.094370894,\n",
            " 'Loss/localization_loss': 0.033451375,\n",
            " 'Loss/regularization_loss': 0.14993273,\n",
            " 'Loss/total_loss': 0.277755,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.606s\n",
            "I0809 15:29:55.598125 140485712877440 model_lib_v2.py:700] Step 1000 per-step time 0.606s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05783013,\n",
            " 'Loss/localization_loss': 0.028203834,\n",
            " 'Loss/regularization_loss': 0.14920421,\n",
            " 'Loss/total_loss': 0.23523816,\n",
            " 'learning_rate': 0.08}\n",
            "I0809 15:29:55.598429 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.05783013,\n",
            " 'Loss/localization_loss': 0.028203834,\n",
            " 'Loss/regularization_loss': 0.14920421,\n",
            " 'Loss/total_loss': 0.23523816,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.614s\n",
            "I0809 15:30:57.019006 140485712877440 model_lib_v2.py:700] Step 1100 per-step time 0.614s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07331721,\n",
            " 'Loss/localization_loss': 0.044941228,\n",
            " 'Loss/regularization_loss': 0.14846885,\n",
            " 'Loss/total_loss': 0.26672727,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0809 15:30:57.019370 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.07331721,\n",
            " 'Loss/localization_loss': 0.044941228,\n",
            " 'Loss/regularization_loss': 0.14846885,\n",
            " 'Loss/total_loss': 0.26672727,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.589s\n",
            "I0809 15:31:55.871419 140485712877440 model_lib_v2.py:700] Step 1200 per-step time 0.589s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.088643864,\n",
            " 'Loss/localization_loss': 0.023947982,\n",
            " 'Loss/regularization_loss': 0.1476825,\n",
            " 'Loss/total_loss': 0.26027435,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0809 15:31:55.871802 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.088643864,\n",
            " 'Loss/localization_loss': 0.023947982,\n",
            " 'Loss/regularization_loss': 0.1476825,\n",
            " 'Loss/total_loss': 0.26027435,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.596s\n",
            "I0809 15:32:55.437749 140485712877440 model_lib_v2.py:700] Step 1300 per-step time 0.596s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06824854,\n",
            " 'Loss/localization_loss': 0.030069165,\n",
            " 'Loss/regularization_loss': 0.14689474,\n",
            " 'Loss/total_loss': 0.24521244,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0809 15:32:55.438087 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.06824854,\n",
            " 'Loss/localization_loss': 0.030069165,\n",
            " 'Loss/regularization_loss': 0.14689474,\n",
            " 'Loss/total_loss': 0.24521244,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.606s\n",
            "I0809 15:33:56.082297 140485712877440 model_lib_v2.py:700] Step 1400 per-step time 0.606s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.091614135,\n",
            " 'Loss/localization_loss': 0.027964793,\n",
            " 'Loss/regularization_loss': 0.14610173,\n",
            " 'Loss/total_loss': 0.26568067,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0809 15:33:56.082618 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.091614135,\n",
            " 'Loss/localization_loss': 0.027964793,\n",
            " 'Loss/regularization_loss': 0.14610173,\n",
            " 'Loss/total_loss': 0.26568067,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.607s\n",
            "I0809 15:34:56.768683 140485712877440 model_lib_v2.py:700] Step 1500 per-step time 0.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045768704,\n",
            " 'Loss/localization_loss': 0.026124287,\n",
            " 'Loss/regularization_loss': 0.14529978,\n",
            " 'Loss/total_loss': 0.21719277,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0809 15:34:56.769042 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.045768704,\n",
            " 'Loss/localization_loss': 0.026124287,\n",
            " 'Loss/regularization_loss': 0.14529978,\n",
            " 'Loss/total_loss': 0.21719277,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.610s\n",
            "I0809 15:35:57.763786 140485712877440 model_lib_v2.py:700] Step 1600 per-step time 0.610s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055423982,\n",
            " 'Loss/localization_loss': 0.022727152,\n",
            " 'Loss/regularization_loss': 0.14449123,\n",
            " 'Loss/total_loss': 0.22264235,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0809 15:35:57.764137 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.055423982,\n",
            " 'Loss/localization_loss': 0.022727152,\n",
            " 'Loss/regularization_loss': 0.14449123,\n",
            " 'Loss/total_loss': 0.22264235,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.598s\n",
            "I0809 15:36:57.605198 140485712877440 model_lib_v2.py:700] Step 1700 per-step time 0.598s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08747574,\n",
            " 'Loss/localization_loss': 0.030788938,\n",
            " 'Loss/regularization_loss': 0.1436843,\n",
            " 'Loss/total_loss': 0.26194897,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0809 15:36:57.605526 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.08747574,\n",
            " 'Loss/localization_loss': 0.030788938,\n",
            " 'Loss/regularization_loss': 0.1436843,\n",
            " 'Loss/total_loss': 0.26194897,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.590s\n",
            "I0809 15:37:56.620559 140485712877440 model_lib_v2.py:700] Step 1800 per-step time 0.590s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.039895978,\n",
            " 'Loss/localization_loss': 0.02535486,\n",
            " 'Loss/regularization_loss': 0.1428834,\n",
            " 'Loss/total_loss': 0.20813425,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0809 15:37:56.620879 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.039895978,\n",
            " 'Loss/localization_loss': 0.02535486,\n",
            " 'Loss/regularization_loss': 0.1428834,\n",
            " 'Loss/total_loss': 0.20813425,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.587s\n",
            "I0809 15:38:55.359710 140485712877440 model_lib_v2.py:700] Step 1900 per-step time 0.587s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07857805,\n",
            " 'Loss/localization_loss': 0.032873943,\n",
            " 'Loss/regularization_loss': 0.14210369,\n",
            " 'Loss/total_loss': 0.25355566,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0809 15:38:55.360078 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.07857805,\n",
            " 'Loss/localization_loss': 0.032873943,\n",
            " 'Loss/regularization_loss': 0.14210369,\n",
            " 'Loss/total_loss': 0.25355566,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.603s\n",
            "I0809 15:39:55.637208 140485712877440 model_lib_v2.py:700] Step 2000 per-step time 0.603s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06851456,\n",
            " 'Loss/localization_loss': 0.027410625,\n",
            " 'Loss/regularization_loss': 0.14133339,\n",
            " 'Loss/total_loss': 0.23725858,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0809 15:39:55.637512 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.06851456,\n",
            " 'Loss/localization_loss': 0.027410625,\n",
            " 'Loss/regularization_loss': 0.14133339,\n",
            " 'Loss/total_loss': 0.23725858,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.603s\n",
            "I0809 15:40:55.947839 140485712877440 model_lib_v2.py:700] Step 2100 per-step time 0.603s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.070627,\n",
            " 'Loss/localization_loss': 0.029584153,\n",
            " 'Loss/regularization_loss': 0.14054558,\n",
            " 'Loss/total_loss': 0.24075672,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0809 15:40:55.948164 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.070627,\n",
            " 'Loss/localization_loss': 0.029584153,\n",
            " 'Loss/regularization_loss': 0.14054558,\n",
            " 'Loss/total_loss': 0.24075672,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.603s\n",
            "I0809 15:41:56.279553 140485712877440 model_lib_v2.py:700] Step 2200 per-step time 0.603s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060245622,\n",
            " 'Loss/localization_loss': 0.020397853,\n",
            " 'Loss/regularization_loss': 0.13978255,\n",
            " 'Loss/total_loss': 0.22042602,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0809 15:41:56.279861 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.060245622,\n",
            " 'Loss/localization_loss': 0.020397853,\n",
            " 'Loss/regularization_loss': 0.13978255,\n",
            " 'Loss/total_loss': 0.22042602,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.595s\n",
            "I0809 15:42:55.786499 140485712877440 model_lib_v2.py:700] Step 2300 per-step time 0.595s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06858173,\n",
            " 'Loss/localization_loss': 0.024008684,\n",
            " 'Loss/regularization_loss': 0.13899797,\n",
            " 'Loss/total_loss': 0.2315884,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0809 15:42:55.786809 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.06858173,\n",
            " 'Loss/localization_loss': 0.024008684,\n",
            " 'Loss/regularization_loss': 0.13899797,\n",
            " 'Loss/total_loss': 0.2315884,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.595s\n",
            "I0809 15:43:55.256973 140485712877440 model_lib_v2.py:700] Step 2400 per-step time 0.595s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047568474,\n",
            " 'Loss/localization_loss': 0.035754014,\n",
            " 'Loss/regularization_loss': 0.13821675,\n",
            " 'Loss/total_loss': 0.22153923,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0809 15:43:55.257319 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.047568474,\n",
            " 'Loss/localization_loss': 0.035754014,\n",
            " 'Loss/regularization_loss': 0.13821675,\n",
            " 'Loss/total_loss': 0.22153923,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.598s\n",
            "I0809 15:44:55.043341 140485712877440 model_lib_v2.py:700] Step 2500 per-step time 0.598s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05253897,\n",
            " 'Loss/localization_loss': 0.027440593,\n",
            " 'Loss/regularization_loss': 0.13745691,\n",
            " 'Loss/total_loss': 0.21743648,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0809 15:44:55.043636 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.05253897,\n",
            " 'Loss/localization_loss': 0.027440593,\n",
            " 'Loss/regularization_loss': 0.13745691,\n",
            " 'Loss/total_loss': 0.21743648,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.607s\n",
            "I0809 15:45:55.715567 140485712877440 model_lib_v2.py:700] Step 2600 per-step time 0.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053111717,\n",
            " 'Loss/localization_loss': 0.019131536,\n",
            " 'Loss/regularization_loss': 0.13669619,\n",
            " 'Loss/total_loss': 0.20893945,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0809 15:45:55.715877 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.053111717,\n",
            " 'Loss/localization_loss': 0.019131536,\n",
            " 'Loss/regularization_loss': 0.13669619,\n",
            " 'Loss/total_loss': 0.20893945,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.608s\n",
            "I0809 15:46:56.509471 140485712877440 model_lib_v2.py:700] Step 2700 per-step time 0.608s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061982892,\n",
            " 'Loss/localization_loss': 0.02693925,\n",
            " 'Loss/regularization_loss': 0.13594699,\n",
            " 'Loss/total_loss': 0.22486913,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0809 15:46:56.509803 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.061982892,\n",
            " 'Loss/localization_loss': 0.02693925,\n",
            " 'Loss/regularization_loss': 0.13594699,\n",
            " 'Loss/total_loss': 0.22486913,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.600s\n",
            "I0809 15:47:56.519462 140485712877440 model_lib_v2.py:700] Step 2800 per-step time 0.600s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04338151,\n",
            " 'Loss/localization_loss': 0.01732354,\n",
            " 'Loss/regularization_loss': 0.13519162,\n",
            " 'Loss/total_loss': 0.19589667,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0809 15:47:56.519775 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.04338151,\n",
            " 'Loss/localization_loss': 0.01732354,\n",
            " 'Loss/regularization_loss': 0.13519162,\n",
            " 'Loss/total_loss': 0.19589667,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.606s\n",
            "I0809 15:48:57.093335 140485712877440 model_lib_v2.py:700] Step 2900 per-step time 0.606s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07076098,\n",
            " 'Loss/localization_loss': 0.04111431,\n",
            " 'Loss/regularization_loss': 0.13443178,\n",
            " 'Loss/total_loss': 0.24630708,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0809 15:48:57.093662 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.07076098,\n",
            " 'Loss/localization_loss': 0.04111431,\n",
            " 'Loss/regularization_loss': 0.13443178,\n",
            " 'Loss/total_loss': 0.24630708,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.607s\n",
            "I0809 15:49:57.779839 140485712877440 model_lib_v2.py:700] Step 3000 per-step time 0.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05502092,\n",
            " 'Loss/localization_loss': 0.015180361,\n",
            " 'Loss/regularization_loss': 0.13366346,\n",
            " 'Loss/total_loss': 0.20386474,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0809 15:49:57.780146 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.05502092,\n",
            " 'Loss/localization_loss': 0.015180361,\n",
            " 'Loss/regularization_loss': 0.13366346,\n",
            " 'Loss/total_loss': 0.20386474,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.614s\n",
            "I0809 15:50:59.137721 140485712877440 model_lib_v2.py:700] Step 3100 per-step time 0.614s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0840313,\n",
            " 'Loss/localization_loss': 0.031590134,\n",
            " 'Loss/regularization_loss': 0.13290516,\n",
            " 'Loss/total_loss': 0.24852659,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0809 15:50:59.138067 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.0840313,\n",
            " 'Loss/localization_loss': 0.031590134,\n",
            " 'Loss/regularization_loss': 0.13290516,\n",
            " 'Loss/total_loss': 0.24852659,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.627s\n",
            "I0809 15:52:01.855662 140485712877440 model_lib_v2.py:700] Step 3200 per-step time 0.627s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.02825863,\n",
            " 'Loss/localization_loss': 0.0147303995,\n",
            " 'Loss/regularization_loss': 0.13215928,\n",
            " 'Loss/total_loss': 0.17514831,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0809 15:52:01.856003 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.02825863,\n",
            " 'Loss/localization_loss': 0.0147303995,\n",
            " 'Loss/regularization_loss': 0.13215928,\n",
            " 'Loss/total_loss': 0.17514831,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.604s\n",
            "I0809 15:53:02.234385 140485712877440 model_lib_v2.py:700] Step 3300 per-step time 0.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03870254,\n",
            " 'Loss/localization_loss': 0.015843676,\n",
            " 'Loss/regularization_loss': 0.13141276,\n",
            " 'Loss/total_loss': 0.18595897,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0809 15:53:02.234724 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.03870254,\n",
            " 'Loss/localization_loss': 0.015843676,\n",
            " 'Loss/regularization_loss': 0.13141276,\n",
            " 'Loss/total_loss': 0.18595897,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.603s\n",
            "I0809 15:54:02.549679 140485712877440 model_lib_v2.py:700] Step 3400 per-step time 0.603s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04437864,\n",
            " 'Loss/localization_loss': 0.016181476,\n",
            " 'Loss/regularization_loss': 0.13067499,\n",
            " 'Loss/total_loss': 0.1912351,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0809 15:54:02.549998 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.04437864,\n",
            " 'Loss/localization_loss': 0.016181476,\n",
            " 'Loss/regularization_loss': 0.13067499,\n",
            " 'Loss/total_loss': 0.1912351,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.608s\n",
            "I0809 15:55:03.337463 140485712877440 model_lib_v2.py:700] Step 3500 per-step time 0.608s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03768687,\n",
            " 'Loss/localization_loss': 0.018488042,\n",
            " 'Loss/regularization_loss': 0.12995315,\n",
            " 'Loss/total_loss': 0.18612805,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0809 15:55:03.337801 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.03768687,\n",
            " 'Loss/localization_loss': 0.018488042,\n",
            " 'Loss/regularization_loss': 0.12995315,\n",
            " 'Loss/total_loss': 0.18612805,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.607s\n",
            "I0809 15:56:04.064985 140485712877440 model_lib_v2.py:700] Step 3600 per-step time 0.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.028802006,\n",
            " 'Loss/localization_loss': 0.01820121,\n",
            " 'Loss/regularization_loss': 0.12923776,\n",
            " 'Loss/total_loss': 0.17624098,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0809 15:56:04.065303 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.028802006,\n",
            " 'Loss/localization_loss': 0.01820121,\n",
            " 'Loss/regularization_loss': 0.12923776,\n",
            " 'Loss/total_loss': 0.17624098,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.683s\n",
            "I0809 15:57:12.374544 140485712877440 model_lib_v2.py:700] Step 3700 per-step time 0.683s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.077253245,\n",
            " 'Loss/localization_loss': 0.024382126,\n",
            " 'Loss/regularization_loss': 0.12850998,\n",
            " 'Loss/total_loss': 0.23014535,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0809 15:57:12.374865 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.077253245,\n",
            " 'Loss/localization_loss': 0.024382126,\n",
            " 'Loss/regularization_loss': 0.12850998,\n",
            " 'Loss/total_loss': 0.23014535,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.687s\n",
            "I0809 15:58:21.034253 140485712877440 model_lib_v2.py:700] Step 3800 per-step time 0.687s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03582196,\n",
            " 'Loss/localization_loss': 0.020664318,\n",
            " 'Loss/regularization_loss': 0.12779729,\n",
            " 'Loss/total_loss': 0.18428357,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0809 15:58:21.034554 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.03582196,\n",
            " 'Loss/localization_loss': 0.020664318,\n",
            " 'Loss/regularization_loss': 0.12779729,\n",
            " 'Loss/total_loss': 0.18428357,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.695s\n",
            "I0809 15:59:30.564192 140485712877440 model_lib_v2.py:700] Step 3900 per-step time 0.695s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.050336502,\n",
            " 'Loss/localization_loss': 0.02752814,\n",
            " 'Loss/regularization_loss': 0.12708582,\n",
            " 'Loss/total_loss': 0.20495045,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0809 15:59:30.564497 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.050336502,\n",
            " 'Loss/localization_loss': 0.02752814,\n",
            " 'Loss/regularization_loss': 0.12708582,\n",
            " 'Loss/total_loss': 0.20495045,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.732s\n",
            "I0809 16:00:43.751533 140485712877440 model_lib_v2.py:700] Step 4000 per-step time 0.732s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046433095,\n",
            " 'Loss/localization_loss': 0.027117237,\n",
            " 'Loss/regularization_loss': 0.12636638,\n",
            " 'Loss/total_loss': 0.1999167,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0809 16:00:43.751854 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.046433095,\n",
            " 'Loss/localization_loss': 0.027117237,\n",
            " 'Loss/regularization_loss': 0.12636638,\n",
            " 'Loss/total_loss': 0.1999167,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.747s\n",
            "I0809 16:01:58.467748 140485712877440 model_lib_v2.py:700] Step 4100 per-step time 0.747s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.056165613,\n",
            " 'Loss/localization_loss': 0.020646444,\n",
            " 'Loss/regularization_loss': 0.12567692,\n",
            " 'Loss/total_loss': 0.20248897,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0809 16:01:58.468102 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.056165613,\n",
            " 'Loss/localization_loss': 0.020646444,\n",
            " 'Loss/regularization_loss': 0.12567692,\n",
            " 'Loss/total_loss': 0.20248897,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.755s\n",
            "I0809 16:03:13.946492 140485712877440 model_lib_v2.py:700] Step 4200 per-step time 0.755s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044766214,\n",
            " 'Loss/localization_loss': 0.016987829,\n",
            " 'Loss/regularization_loss': 0.12497899,\n",
            " 'Loss/total_loss': 0.18673304,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0809 16:03:13.946815 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.044766214,\n",
            " 'Loss/localization_loss': 0.016987829,\n",
            " 'Loss/regularization_loss': 0.12497899,\n",
            " 'Loss/total_loss': 0.18673304,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.817s\n",
            "I0809 16:04:35.611308 140485712877440 model_lib_v2.py:700] Step 4300 per-step time 0.817s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07275327,\n",
            " 'Loss/localization_loss': 0.027107991,\n",
            " 'Loss/regularization_loss': 0.12427792,\n",
            " 'Loss/total_loss': 0.22413918,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0809 16:04:35.611639 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.07275327,\n",
            " 'Loss/localization_loss': 0.027107991,\n",
            " 'Loss/regularization_loss': 0.12427792,\n",
            " 'Loss/total_loss': 0.22413918,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.891s\n",
            "I0809 16:06:04.719044 140485712877440 model_lib_v2.py:700] Step 4400 per-step time 0.891s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.065364964,\n",
            " 'Loss/localization_loss': 0.029065285,\n",
            " 'Loss/regularization_loss': 0.12360029,\n",
            " 'Loss/total_loss': 0.21803054,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0809 16:06:04.719406 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.065364964,\n",
            " 'Loss/localization_loss': 0.029065285,\n",
            " 'Loss/regularization_loss': 0.12360029,\n",
            " 'Loss/total_loss': 0.21803054,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.889s\n",
            "I0809 16:07:33.595344 140485712877440 model_lib_v2.py:700] Step 4500 per-step time 0.889s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055398997,\n",
            " 'Loss/localization_loss': 0.019455062,\n",
            " 'Loss/regularization_loss': 0.12292648,\n",
            " 'Loss/total_loss': 0.19778055,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0809 16:07:33.595686 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.055398997,\n",
            " 'Loss/localization_loss': 0.019455062,\n",
            " 'Loss/regularization_loss': 0.12292648,\n",
            " 'Loss/total_loss': 0.19778055,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.941s\n",
            "I0809 16:09:07.666651 140485712877440 model_lib_v2.py:700] Step 4600 per-step time 0.941s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036653902,\n",
            " 'Loss/localization_loss': 0.014178729,\n",
            " 'Loss/regularization_loss': 0.12223782,\n",
            " 'Loss/total_loss': 0.17307045,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0809 16:09:07.666996 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.036653902,\n",
            " 'Loss/localization_loss': 0.014178729,\n",
            " 'Loss/regularization_loss': 0.12223782,\n",
            " 'Loss/total_loss': 0.17307045,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.842s\n",
            "I0809 16:10:31.876961 140485712877440 model_lib_v2.py:700] Step 4700 per-step time 0.842s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03474977,\n",
            " 'Loss/localization_loss': 0.01499545,\n",
            " 'Loss/regularization_loss': 0.12156824,\n",
            " 'Loss/total_loss': 0.17131346,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0809 16:10:31.877483 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.03474977,\n",
            " 'Loss/localization_loss': 0.01499545,\n",
            " 'Loss/regularization_loss': 0.12156824,\n",
            " 'Loss/total_loss': 0.17131346,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.864s\n",
            "I0809 16:11:58.264464 140485712877440 model_lib_v2.py:700] Step 4800 per-step time 0.864s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044939954,\n",
            " 'Loss/localization_loss': 0.015155166,\n",
            " 'Loss/regularization_loss': 0.12090628,\n",
            " 'Loss/total_loss': 0.1810014,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0809 16:11:58.264891 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.044939954,\n",
            " 'Loss/localization_loss': 0.015155166,\n",
            " 'Loss/regularization_loss': 0.12090628,\n",
            " 'Loss/total_loss': 0.1810014,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.860s\n",
            "I0809 16:13:24.306515 140485712877440 model_lib_v2.py:700] Step 4900 per-step time 0.860s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.025841484,\n",
            " 'Loss/localization_loss': 0.015711516,\n",
            " 'Loss/regularization_loss': 0.12024037,\n",
            " 'Loss/total_loss': 0.16179337,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0809 16:13:24.306886 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.025841484,\n",
            " 'Loss/localization_loss': 0.015711516,\n",
            " 'Loss/regularization_loss': 0.12024037,\n",
            " 'Loss/total_loss': 0.16179337,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.800s\n",
            "I0809 16:14:44.259723 140485712877440 model_lib_v2.py:700] Step 5000 per-step time 0.800s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03195833,\n",
            " 'Loss/localization_loss': 0.0086889705,\n",
            " 'Loss/regularization_loss': 0.119564116,\n",
            " 'Loss/total_loss': 0.16021141,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0809 16:14:44.260080 140485712877440 model_lib_v2.py:701] {'Loss/classification_loss': 0.03195833,\n",
            " 'Loss/localization_loss': 0.0086889705,\n",
            " 'Loss/regularization_loss': 0.119564116,\n",
            " 'Loss/total_loss': 0.16021141,\n",
            " 'learning_rate': 0.078691795}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XO4Bry5FKxJ"
      },
      "source": [
        "# 7. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBv4TC_6t7Dq",
        "outputId": "d104fddb-8f26-4322-efc2-899bbc6c56bd"
      },
      "source": [
        "#Adding models folder paths to PYTHONPATH variables so python can find the modules needed.\n",
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research/\"\n",
        "os.environ['PYTHONPATH'] += \":/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research/slim\"\n",
        "! echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python\n",
            "/env/python:/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research/:/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/models/research/slim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHhmV77yFKxJ"
      },
      "source": [
        "import os\n",
        "# %tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "from object_detection.protos import model_pb2\n",
        "# from tensorflow.contrib import slim\n",
        "from nets import inception_resnet_v2\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSOw9vXeFKxJ"
      },
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "# detection_model = model_builder.build(model_config='/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config', is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join('/content/drive/MyDrive/Applied ML/FaceMaskNew/Tensorflow/workspace/models/my_ssd_mobnet', 'ckpt-6')).expect_partial()\n",
        "\n",
        "#This is where the detection happens.\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6ykt7PFKxK"
      },
      "source": [
        "# 8. Detect in Real-Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smVikfZkFKxK"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIDh_o3HFKxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1680bb50-9544-4ca1-cff7-3e11c2fff4e4"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/labelmap.pbtxt')\n",
        "category_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'id': 1, 'name': 'Face_mask_found'},\n",
              " 2: {'id': 2, 'name': 'Face_mask_not_found'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr5L9xbrFKxK"
      },
      "source": [
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1pTEUwpFKxK"
      },
      "source": [
        "# Setup capture\n",
        "cap = cv2.VideoCapture('0')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuB1EUEqdLIJ"
      },
      "source": [
        "##Since opencv is not fully supported in Google Colab. The Final Execution is done using face_mask_detector.py file which is run in PyCharm. This file only has the code for execution, as the model training and the pre-processing parts of the project have been executed here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ4kOGAbFKxK"
      },
      "source": [
        "while True: \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    #The input from the camera has to be converted to tensors.\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.5,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    # cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    #Attempted to run cv2_imshow since cv2.imshow is not available in google colab.\n",
        "    cv2_imshow(cv2.resize(image_np_with_detections, (800,600)))\n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}